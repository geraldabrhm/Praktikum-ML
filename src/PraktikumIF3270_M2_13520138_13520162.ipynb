{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediksi Hujan di Denpasar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praktikum ini menggunakan _dataset_ [Denpasar Weather Data](https://www.kaggle.com/datasets/cornflake15/denpasarbalihistoricalweatherdata?select=openweatherdata-denpasar-1990-2020v0.1.csv) dengan modifikasi. _Dataset_ digunakan untuk melakukan prediksi penarikan kesimpulan kebenaran kondisi hujan pada kondisi tertentu. Hal itu diperoleh dengan meninjau `raining` (diekstrak dari `weather_main`) sebagai target. Fitur yang digunakan adalah sebagai berikut:\n",
    "- `hour` (diekstrak dari `dt_iso`)\n",
    "- `temp`\n",
    "- `temp_min`\n",
    "- `temp_max`\n",
    "- `pressure`\n",
    "- `humidity`\n",
    "- `wind_speed`\n",
    "- `wind_deg`\n",
    "\n",
    "Tujuan praktikum:\n",
    "1.   Peserta memahami rangkaian proses analitik data menggunakan pendekatan pembelajaran mesin. \n",
    "2.   Peserta memahami bahwa proses pengembangan model pembelajaran mesin juga ditentukan dari kualitas data, penanganan data, dan penentuan algoritma serta hiperparameternya; tidak cukup hanya dengan memastikan implementasi algoritma berjalan tanpa kesalahan.\n",
    "3.   Peserta mampu menginterpretasikan hasil dari evaluasi model dalam proses analitik menggunakan pendekatan pembelajaran mesin.\n",
    "\n",
    "Praktikum dilaksanakan secara berkelompok. Setiap kelompok terdiri atas 2 mahasiswa. Perhatikan bahwa terdapat berkas yang harus dikumpulkan sebelum waktu praktikum selesai (17 April 2023, pukul 10.59 WIB) dan berkas yang dikumpulkan setelah waktu praktikum selesai (17 April 2023, pukul 23.59 WIB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persiapan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>raining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25.82</td>\n",
       "      <td>25.82</td>\n",
       "      <td>25.82</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.36</td>\n",
       "      <td>225</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26.20</td>\n",
       "      <td>26.20</td>\n",
       "      <td>26.20</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2.09</td>\n",
       "      <td>247</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26.45</td>\n",
       "      <td>26.45</td>\n",
       "      <td>26.45</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2.44</td>\n",
       "      <td>262</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>26.80</td>\n",
       "      <td>26.80</td>\n",
       "      <td>26.80</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2.29</td>\n",
       "      <td>271</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>27.04</td>\n",
       "      <td>27.04</td>\n",
       "      <td>27.04</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1.71</td>\n",
       "      <td>274</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour   temp  temp_min  temp_max  pressure  humidity  wind_speed  wind_deg  \\\n",
       "0     0  25.82     25.82     25.82    1010.0        86        1.36       225   \n",
       "1     1  26.20     26.20     26.20    1011.0        84        2.09       247   \n",
       "2     2  26.45     26.45     26.45    1011.0        84        2.44       262   \n",
       "3     3  26.80     26.80     26.80    1011.0        82        2.29       271   \n",
       "4     4  27.04     27.04     27.04    1010.0        82        1.71       274   \n",
       "\n",
       "   raining  \n",
       "0     True  \n",
       "1     True  \n",
       "2     True  \n",
       "3     True  \n",
       "4    False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/openweatherdata-denpasar-1990-2020v0.1-simplified.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=\"raining\")\n",
    "y = data[\"raining\"].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=123)\n",
    "\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_val = pd.concat([X_val, y_val], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disediakan data yang sudah dibagi menjadi data latih (`df_train`), data validasi (`df_val`), dan data uji (`df_test`).\n",
    "\n",
    "**Bagian 1**: (batas waktu: 17 April 2023, 10.59 WIB)\n",
    "\n",
    "1. Buatlah _baseline_ dengan menggunakan model _logistic regression_.\n",
    "2. Lakukan analisis data terkait hal berikut:\n",
    "    - _duplicate value_,\n",
    "    - _missing value_,\n",
    "    - _outlier_,\n",
    "    - _balance of data_.\n",
    "3. Jelaskan rencana penanganan yang ada pada poin 2.\n",
    "4. Jelaskan teknik _encoding_ yang digunakan terhadap data yang disediakan, disertai dengan alasan.\n",
    "5. Buatlah desain eksperimen dengan menentukan hal berikut:\n",
    "    - tujuan eksperimen,\n",
    "    - variabel dependen dan independen,\n",
    "    - strategi eksperimen,\n",
    "    - skema validasi.\n",
    "    \n",
    "**Bagian 2**: (batas waktu: 17 April 2023, 23.59 WIB)\n",
    "\n",
    "6. Implementasikan strategi eksperimen dan skema validasi yang telah ditentukan pada poin 5.\n",
    "7. Berdasarkan hasil prediksi yang dihasilkan, buatlah kesimpulan analisis karakteristik kondisi hujan.\n",
    "\n",
    "---\n",
    "\n",
    "Jika terdapat perubahan jawaban pada poin 1â€”5 (contoh: perbedaan penanganan _outlier_), jelaskan pada laporan mengenai jawaban sebelum, jawaban sesudah, dan alasan pengubahan jawaban."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| NIM          | Nama       | Bagian pengerjaan      |\n",
    "| -------------- | -------------- | -------------- |\n",
    "| 13520138 | Gerald Abraham Sianturi| Baseline, analisis duplicate value, analisis missing value, analisis outlier, penanganan duplicate value, penanganan missing value, penanganan outlier, variabel dependen dan independen, strategi eksperimen. Implementasi penanganan duplicate value, implementasi penanganan missing value, implementasi penanganan outlier, hyperparameter tuning, validasi. Laporan| \n",
    "| 13520162 | Daffa Romyz Aufa        | Analisis imbalance dataset, penanganan imbalance dataset, teknik encoding, tujuan eksperimen, skema validasi. Implementasi penanganan imbalance dataset. Laporan | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Deliverable_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Deliverable_ yang akan dihasilkan adalah sebagai berikut:\n",
    "1. berkas _notebook_ dengan format nama `PraktikumIF3270_M1_NIM1_NIM2.ipynb` untuk Bagian 1;\n",
    "2. berkas _notebook_ dengan format nama `PraktikumIF3270_M2_NIM1_NIM2.ipynb` untuk Bagian 1 + Bagian 2; serta\n",
    "3. berkas laporan dengan format nama `PraktikumIF3270_NIM1_NIM2.pdf` yang mencakup hal berikut:\n",
    "    - hasil analisis data,\n",
    "    - penanganan dari hasil analisis data,\n",
    "    - justifikasi teknik-teknik yang dipilih,\n",
    "    - perubahan yang dilakukan pada jawaban poin 1â€”5 jika ada,\n",
    "    - desain eksperimen,\n",
    "    - hasil eksperimen.\n",
    "    - analisis dari hasil eksperimen,\n",
    "    - kesimpulan,\n",
    "    - pembagian tugas/kerja per anggota kelompok\n",
    "\n",
    "Batas waktu pengumpulan:\n",
    "- _Deliverable_ poin 1: Senin, 17 April 2023, pukul 10.59 WIB\n",
    "- _Deliverable_ poin 2: Senin, 17 April 2023, pukul 23.59 WIB\n",
    "- _Deliverable_ poin 3: Senin, 17 April 2023, pukul 23.59 WIB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDataWithNewChange(df):\n",
    "  features = list(df.columns)\n",
    "  features.remove('raining')\n",
    "  \n",
    "  numericFeaturesDf = df.select_dtypes(include=['float64', 'int64'])\n",
    "  numericFeatures = list(numericFeaturesDf.columns)\n",
    "  \n",
    "  categoricalFeaturesDf = df.select_dtypes(include=['bool'])\n",
    "  categoricalFeaturesDf = categoricalFeaturesDf.drop(columns=['raining'])\n",
    "  categoricalFeatures = list(categoricalFeaturesDf.columns)\n",
    "  \n",
    "  return features, numericFeaturesDf, numericFeatures, categoricalFeaturesDf, categoricalFeatures\n",
    "\n",
    "features, numericFeaturesDf, numericFeatures, categoricalFeaturesDf, categoricalFeatures = updateDataWithNewChange(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Buatlah _baseline_ dengan menggunakan model _logistic regression_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_test_predict_log = logreg.predict(X_test)\n",
    "y_train_predict_log = logreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation metric pada test set dengan logistic regression ===\n",
      "Skor akurasi pada test set: 0.8728\n",
      "Skor precision pada test set: 0.5819\n",
      "Skor recall pada test set: 0.128\n",
      "Skor f1 pada test set: 0.2099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def displayEvaluationMetric(y_test, y_test_predict, name_of_set: str, \n",
    "name_of_model: str):\n",
    "  accuracyTestSet = accuracy_score(y_test, y_test_predict)\n",
    "  precisionTestSet = precision_score(y_test, y_test_predict)\n",
    "  recallTestSet = recall_score(y_test, y_test_predict)\n",
    "  f1TestSet = f1_score(y_test, y_test_predict)\n",
    "  print(f\"=== Evaluation metric pada {name_of_set} set dengan {name_of_model} ===\")\n",
    "  print(f\"Skor akurasi pada test set: {round(accuracyTestSet, 4)}\")\n",
    "  print(f\"Skor precision pada test set: {round(precisionTestSet, 4)}\")\n",
    "  print(f\"Skor recall pada test set: {round(recallTestSet, 4)}\")\n",
    "  print(f\"Skor f1 pada test set: {round(f1TestSet, 4)}\\n\")\n",
    "  \n",
    "displayEvaluationMetric(y_test, y_test_predict_log, \"test\", \"logistic regression\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Lakukan analisis data terkait duplicate/missing value, outlier, dan balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyak nilai duplikat: 7253\n"
     ]
    }
   ],
   "source": [
    "# Duplicate value\n",
    "countOfDuplicateValue = data.duplicated().value_counts()[1]\n",
    "print(f\"Banyak nilai duplikat: {countOfDuplicateValue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour: 0 (0.0 %)\n",
      "temp: 0 (0.0 %)\n",
      "temp_min: 0 (0.0 %)\n",
      "temp_max: 0 (0.0 %)\n",
      "pressure: 0 (0.0 %)\n",
      "humidity: 0 (0.0 %)\n",
      "wind_speed: 0 (0.0 %)\n",
      "wind_deg: 0 (0.0 %)\n",
      "raining: 0 (0.0 %)\n"
     ]
    }
   ],
   "source": [
    "# Missing value\n",
    "numOfRows = data.shape[0]\n",
    "\n",
    "listOfCountMissingVal = data.isna().sum().values\n",
    "for i, col in enumerate(data):\n",
    "  numOfMissingValue = listOfCountMissingVal[i]\n",
    "  proportionOfMissingValue = round(numOfMissingValue / numOfRows * \n",
    "100, 2)\n",
    "  print(f\"{col}: {numOfMissingValue} ({proportionOfMissingValue} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour: 0 (0.0 %)\n",
      "temp: 1458 (0.55 %)\n",
      "temp_min: 1716 (0.65 %)\n",
      "temp_max: 547 (0.21 %)\n",
      "pressure: 1067 (0.4 %)\n",
      "humidity: 231 (0.09 %)\n",
      "wind_speed: 3439 (1.3 %)\n",
      "wind_deg: 0 (0.0 %)\n"
     ]
    }
   ],
   "source": [
    "# Outlier\n",
    "numericFeatNoOutlier = []\n",
    "for feature in numericFeatures:\n",
    "  Q1 = X[feature].quantile(0.25)\n",
    "  Q3 = X[feature].quantile(0.75)\n",
    "  IQR = round(Q3 - Q1, 2)\n",
    "  countOutlier = ((X[feature] < (Q1 - 1.5 * IQR)) | (X[feature] > (Q3 \n",
    "+ 1.5 * IQR))).sum()\n",
    "  proportionOutlier = round(countOutlier / numOfRows * 100, 2)\n",
    "  print(f\"{feature}: {countOutlier} ({proportionOutlier} %)\")\n",
    "  if(countOutlier == 0):\n",
    "    numericFeatNoOutlier.append(feature)\n",
    "\n",
    "numericFeatWithOutlier = list(set(numericFeatures) - set(numericFeatNoOutlier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class True =  34901 ; Class False = 230023\n"
     ]
    }
   ],
   "source": [
    "# Balance of data\n",
    "df_true = data[data[\"raining\"] == True]\n",
    "df_false = data[data[\"raining\"] == False]\n",
    "print( \"Class True = \", len(df_true), \"; Class False =\", len(df_false))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Rencana penanganan yang ada pada poin 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penanganan duplicate value\n",
    "Duplicate value ditangani dengan menghapus row yang merupakan duplicate value. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penangangan missing value\n",
    "Tidak terdapat missing value sehingga penanganan tidak dilakukan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penangangan outlier\n",
    "Tidak dilakukan penghapusan data yang mengandung nilai outlier karena pada kasus ini, jumlah outlier proporsinya kecil dan kami melihat bahwa outlier pada dataset yang ada dapat memberikan insight pada data dan menunjukkan pola tertentu."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penangangan imbalance dataset\n",
    "Imbalance dataset ditangani dengan teknik oversampling. Terdapat dua kelas yaitu kelas True dan kelas False. Kelas True merupakan kelas minoritas yang akan diduplikasi sehingga memiliki jumlah yang mirip dengan kelas False. Pemilihan teknik oversampling dari pada undersampling adalah agar informasi pada kelas mayoritas tidak hilang. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Teknik _encoding_ yang digunakan terhadap data yang disediakan, disertai dengan alasan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding dilakukan pada kolom raining, yang merupakan target columns. Teknik encoding yang dilakukan adalah integer encoding, yakni dengan:\n",
    "\n",
    "- Nilai False akan diencode menjadi nilai 0. \n",
    "- Nilai True aka diencode menjadi nilai 1. \n",
    "\n",
    "Hal ini mengikuti nilai boolean dimana False bernilai 0 dan True bernilai 1. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Desain eksperimen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tujuan eksperimen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperimen dilakukan untuk mengoptimalkan performa model dengan menggunakan data yang ada. Perfoma yang diinginkan dari eksperimen ini adalah seberapa benarnya prediksi model pada kelas True karena merupakan kelas minoritas dari imbalace dataset. Performa akan dicari adalah nilai f1 dan recall yang besar tanpa mengorbankan precision."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variabel dependen dan independen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada kasus ini, variabel independennya adalah fitur-fitur yang ada, yakni hour, temp, temp_min, temp_max, pressure, humidity, wind_speed, dan wind_deg. Sedangkan variabel dependennya adalah kolom target, yakni raining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategi eksperimen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperimen dilakukan _hyperparameter tuning_ pada parameter logistic regression."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skema validasi\n",
    "Validasi dilakukan dengan menggunakan data validasi (df_val). Data validasi akan diprediksi kelasnya dengan model. Hasil prediksi tersebut akan dibandingkan dengan kelas aslinya. Metrik yang digunakan adalah accuracy, precision, recall, dan f1. Model yang dipilih adalah model yang memiliki nilai recall dan f1 yang baik tanpa mengorbankan precision."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle duplicate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>raining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25.82</td>\n",
       "      <td>25.82</td>\n",
       "      <td>25.82</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.36</td>\n",
       "      <td>225</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26.20</td>\n",
       "      <td>26.20</td>\n",
       "      <td>26.20</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2.09</td>\n",
       "      <td>247</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26.45</td>\n",
       "      <td>26.45</td>\n",
       "      <td>26.45</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2.44</td>\n",
       "      <td>262</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>26.80</td>\n",
       "      <td>26.80</td>\n",
       "      <td>26.80</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2.29</td>\n",
       "      <td>271</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>27.04</td>\n",
       "      <td>27.04</td>\n",
       "      <td>27.04</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1.71</td>\n",
       "      <td>274</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour   temp  temp_min  temp_max  pressure  humidity  wind_speed  wind_deg  \\\n",
       "0     0  25.82     25.82     25.82    1010.0        86        1.36       225   \n",
       "1     1  26.20     26.20     26.20    1011.0        84        2.09       247   \n",
       "2     2  26.45     26.45     26.45    1011.0        84        2.44       262   \n",
       "3     3  26.80     26.80     26.80    1011.0        82        2.29       271   \n",
       "4     4  27.04     27.04     27.04    1010.0        82        1.71       274   \n",
       "\n",
       "   raining  \n",
       "0     True  \n",
       "1     True  \n",
       "2     True  \n",
       "3     True  \n",
       "4    False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_drop_duplicate = data.drop_duplicates()\n",
    "X_drop_duplicate, y_drop_duplicate = data_drop_duplicate[features], data_drop_duplicate['raining']\n",
    "data_drop_duplicate.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle variance of range in the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>raining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.455598</td>\n",
       "      <td>-0.491667</td>\n",
       "      <td>-0.393333</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>-0.828996</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.916667</td>\n",
       "      <td>-0.308880</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.557621</td>\n",
       "      <td>0.881944</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.833333</td>\n",
       "      <td>-0.212355</td>\n",
       "      <td>-0.229167</td>\n",
       "      <td>-0.183333</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.077220</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.483271</td>\n",
       "      <td>1.048611</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.698885</td>\n",
       "      <td>1.069444</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour      temp  temp_min  temp_max  pressure  humidity  wind_speed  \\\n",
       "0 -1.000000 -0.455598 -0.491667 -0.393333 -0.057143  0.214286   -0.828996   \n",
       "1 -0.916667 -0.308880 -0.333333 -0.266667  0.228571  0.071429   -0.557621   \n",
       "2 -0.833333 -0.212355 -0.229167 -0.183333  0.228571  0.071429   -0.427509   \n",
       "3 -0.750000 -0.077220 -0.083333 -0.066667  0.228571 -0.071429   -0.483271   \n",
       "4 -0.666667  0.015444  0.016667  0.013333 -0.057143 -0.071429   -0.698885   \n",
       "\n",
       "   wind_deg  raining  \n",
       "0  0.729167     True  \n",
       "1  0.881944     True  \n",
       "2  0.986111     True  \n",
       "3  1.048611     True  \n",
       "4  1.069444    False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_res = RobustScaler().fit_transform(X_drop_duplicate)\n",
    "\n",
    "X_scaled = pd.DataFrame(X_scaled_res, columns = features)\n",
    "y_drop_duplicate = pd.DataFrame(y_drop_duplicate)\n",
    "\n",
    "df_scaled = pd.concat([X_scaled.reset_index(drop=True), y_drop_duplicate.reset_index(drop=True)], axis=1)\n",
    "df_scaled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarisasi pada target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>raining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.455598</td>\n",
       "      <td>-0.491667</td>\n",
       "      <td>-0.393333</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>-0.828996</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.916667</td>\n",
       "      <td>-0.308880</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.557621</td>\n",
       "      <td>0.881944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.833333</td>\n",
       "      <td>-0.212355</td>\n",
       "      <td>-0.229167</td>\n",
       "      <td>-0.183333</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.077220</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.483271</td>\n",
       "      <td>1.048611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.698885</td>\n",
       "      <td>1.069444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour      temp  temp_min  temp_max  pressure  humidity  wind_speed  \\\n",
       "0 -1.000000 -0.455598 -0.491667 -0.393333 -0.057143  0.214286   -0.828996   \n",
       "1 -0.916667 -0.308880 -0.333333 -0.266667  0.228571  0.071429   -0.557621   \n",
       "2 -0.833333 -0.212355 -0.229167 -0.183333  0.228571  0.071429   -0.427509   \n",
       "3 -0.750000 -0.077220 -0.083333 -0.066667  0.228571 -0.071429   -0.483271   \n",
       "4 -0.666667  0.015444  0.016667  0.013333 -0.057143 -0.071429   -0.698885   \n",
       "\n",
       "   wind_deg  raining  \n",
       "0  0.729167        1  \n",
       "1  0.881944        1  \n",
       "2  0.986111        1  \n",
       "3  1.048611        1  \n",
       "4  1.069444        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled['raining'] = df_scaled['raining'].map({True: 1, False: 0})\n",
    "final_df = df_scaled\n",
    "final_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi strategi eksperimen dan skema validasi yang telah ditentukan pada poin 5."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Men-_generate_ data baru (hasil pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns=\"raining\")\n",
    "y = final_df[\"raining\"].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=123)\n",
    "\n",
    "# Oversampling \n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_true = df_train[df_train[\"raining\"] == True]\n",
    "df_false = df_train[df_train[\"raining\"] == False]\n",
    "df_mayor = df_false\n",
    "df_minor = df_true\n",
    "n_mayor = len(df_false)\n",
    "n_minor = len(df_true)\n",
    "df_over = df_minor.sample(n_mayor, replace=True)\n",
    "df_oversample = pd.concat([df_mayor, df_over])\n",
    "X_OS_train = df_oversample.drop(columns=[\"raining\"])\n",
    "y_OS_train = df_oversample[\"raining\"]\n",
    "\n",
    "df_val = pd.concat([X_val, y_val], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning dan mencari parameter terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to 0.0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\geral\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=0.0, estimator=LogisticRegression(random_state=0),\n",
       "             param_grid={&#x27;C&#x27;: [0.5, 1.0, 10.0],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cholesky&#x27;, &#x27;lbfgs&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=0.0, estimator=LogisticRegression(random_state=0),\n",
       "             param_grid={&#x27;C&#x27;: [0.5, 1.0, 10.0],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cholesky&#x27;, &#x27;lbfgs&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score=0.0, estimator=LogisticRegression(random_state=0),\n",
       "             param_grid={'C': [0.5, 1.0, 10.0],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cholesky', 'lbfgs']})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_new = LogisticRegression(random_state=0)\n",
    "logreg_new.fit(X_OS_train, y_OS_train)\n",
    "listParam = {\n",
    "    'C': [0.5, 1.0, 10.0],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['newton-cholesky', 'lbfgs']\n",
    "}\n",
    "\n",
    "logreg_variant = GridSearchCV(logreg_new, listParam, error_score=0.0)\n",
    "logreg_variant.fit(X_OS_train, y_OS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Best Parameter ===\n",
      "{'C': 0.5, 'penalty': 'l2', 'solver': 'lbfgs'} \n",
      "\n",
      "=== Metrik Evaluasi ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.71      0.81     35695\n",
      "           1       0.29      0.74      0.41      5533\n",
      "\n",
      "    accuracy                           0.72     41228\n",
      "   macro avg       0.62      0.73      0.61     41228\n",
      "weighted avg       0.86      0.72      0.76     41228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Best Parameter ===\")\n",
    "best_param = logreg_variant.best_params_\n",
    "print(best_param, \"\\n\")\n",
    "\n",
    "print(\"=== Metrik Evaluasi ===\")\n",
    "logreg_variant_val_predict = logreg_variant.predict(X_val)\n",
    "print(classification_report(y_val, logreg_variant_val_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation metric pada test set dengan logistic regression tuning ===\n",
      "Skor akurasi pada test set: 0.7183\n",
      "Skor precision pada test set: 0.2918\n",
      "Skor recall pada test set: 0.7472\n",
      "Skor f1 pada test set: 0.4197\n",
      "\n",
      "=== Evaluation metric pada training set dengan logistic regression tuning ===\n",
      "Skor akurasi pada test set: 0.728\n",
      "Skor precision pada test set: 0.7206\n",
      "Skor recall pada test set: 0.7447\n",
      "Skor f1 pada test set: 0.7324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_tuning = LogisticRegression(C=best_param['C'], penalty=best_param['penalty'], solver=best_param['solver'], random_state=0)\n",
    "logreg_tuning.fit(X_OS_train, y_OS_train)\n",
    "\n",
    "y_test_predict_log_tuning = logreg_tuning.predict(X_test)\n",
    "y_train_predict_log_tuning = logreg_tuning.predict(X_OS_train) # Untuk pengecekan underfitting atau overfitting\n",
    "\n",
    "displayEvaluationMetric(y_test, y_test_predict_log_tuning, \"test\", \"logistic regression tuning\")\n",
    "displayEvaluationMetric(y_OS_train, y_train_predict_log_tuning, \"training\", \"logistic regression tuning\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validasi dengan cross validation (k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.872 0.847 0.864 0.854 0.878 0.862 0.881 0.891 0.876 0.879]\n",
      "Means: 0.87; standar deviasi: 0.013\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logreg, X, y, cv=10).round(decimals=3)\n",
    "print(scores)\n",
    "print(f\"Means: {round(scores.mean(), 3)}; standar deviasi: {round(scores.std(), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.872 0.847 0.864 0.854 0.878 0.862 0.881 0.891 0.876 0.879]\n",
      "Means: 0.87; standar deviasi: 0.013\n"
     ]
    }
   ],
   "source": [
    "scores_1 = cross_val_score(logreg_tuning, X, y, cv=10).round(decimals=3)\n",
    "print(scores_1)\n",
    "print(f\"Means: {round(scores_1.mean(), 3)}; standar deviasi: {round(scores_1.std(), 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil Eksperimen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model          | Accuracy       | Precision      | Recall           | F1 score       |\n",
    "| -------------- | -------------- | -------------- | -------------- | -------------- |\n",
    "| Baseline | 0.8728         | 0.5819         | 0.128         | 0.2099            |\n",
    "| Eksperimen | 0.7177         | 0.2912         | 0.7468         | 0.419            |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis hasil eksperimen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model baseline memiliki akurasi yang tinggi, yakni 0.8728, yang berarti model dapat memprediksi 87% dari keseluruhan test set dengan benar. Namun, ketika memprediksi true positive (kasus raining = true atau raining terjadi), model memberikan banyak prediksi keliru. Nilai precision sebesar 0.5819 mengindikasikan bahwa dari seluruh hasil prediksi model yang memprediksi raining = true, hanya 58% yang benar. Nilai f1 cukup kecil yang menunjukkan ketidakseimbangan antara nilai precision dan recall.\n",
    "\n",
    "Setelah dilakukan eksperimen, nilai akurasi cukup tinggi, yakni dapat memprediksi 71% test set dengan benar. Ketika memprediksi ketika memprediksi true positive (kasus raining = true atau raining benar terjadi), model memberikan prediksi yang jauh lebih baik dibandingkan sebelum dilakukan eksperimen. Namun, ketika model memprediksi raining = true, hanya 29% yang prediksinya tepat. Walaupun nilai f1 yang menunjukkan keseimbangan trade-off antara nilai precision dan recall lebih baik dibandingkan model baseline, skor ini tergolong kecil."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kesimpulan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan metrik evaluasi yang diperoleh, terdapat peningkatan pada metrik recall dan f1, dan sebaliknya terdapat pengurangan angka accuracy dan precision setelah dilakukan eksperimen. Dengan demikian, dengan memperhatikan trade-off antara metrik yang ada, model hasil eksperimen memberikan hasil yang lebih baik karena untuk kasus memprediksi apakah hujan benar terjadi atau tidak, kita lebih memperhatikan cost dari false negative (nilai recall), yakni rain sebenarnya bernilai true tetapi prediksinya false, seperti tidak membawa payung ketika sebenaranya hujan, akan jauh lebih diperhatikan."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
